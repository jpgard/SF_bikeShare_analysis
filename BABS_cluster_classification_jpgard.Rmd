---
title: "STATS 415 Final Project"
author: "Joshua Gardner"
date: "April 15, 2016"
output: html_document
---

#Introduction

The questions of interest for this analysis are: 

*Can we find distinct clusters of riders, based on the features available in the Bay Area Bike Share open dataset?
*Can we predict ride length (short, medium, or long) using k-nearest neighbors classification?

#The Data

This analysis uses three different datasets provided as part of the Bay Area Bike Share (BABS) open dataset. Files contain data from  3/1/14 to 8/31/14.

####Station Information:

FILE = "201408_station_data.csv"


*station_id: station ID number (corresponds to "station_id" in "201408_status_data.csv")
*name: name of station
*lat: latitude
*long: longitude
*dockcount: number of total docks at station
*landmark: city (San Francisco, Redwood City, Palo Alto, Mountain View, San Jose)
*installation: date that station was installed 

####Trip Data:

FILE = "201408_trip_data.csv"


-Trip ID: numeric ID of bike trip
-Duration: time of trip in seconds
-Start Date: start date of trip with date and time, in PST
-Start Station: station name of start station
-Start Terminal: numeric reference for start station
-End Date: end date of trip with date and time, in PST
-End Station: station name for end station
-End Terminal: numeric reference for end station
-Bike #: ID of bike used
-Subscription Type: Subscriber = annual member; Customer = 24-hour or 3-day member
-Zip Code: Home zip code of user (only available for annual members)


####Weather Data:

FILE = "201408_weather_data.csv"
Daily weather information per service area. Weather is listed from north to south (San Francisco, Redwood City, Palo Alto, Mountain View, San Jose).
    
-Max_Visibility_Miles 	
-Mean_Visibility_Miles 	
-Min_Visibility_Miles 	 		
-Precipitation_In 	"numeric, in form x.xx but alpha ""T""= trace when amount less than .01 inch"	
-Cloud_Cover 	"scale of 0-8, 0=clear"	
-Events	"text field - entries: rain, fog, thunderstorm"	
-zip code: 94107=San Francisco, 94063=Redwood City, 94301=Palo Alto, 94041=Mountain View, 95113= San Jose"

#Analysis and Methods


```{r}
library(plyr)
library(tidyr)
library(ggmap)
library(qdapRegex)
library(geosphere)


stationdata = read.csv("201408_babs_open_data/201408_station_data.csv")
tripdata = read.csv("201408_babs_open_data/201408_trip_data.csv")
weatherdata = read.csv("201408_babs_open_data/201408_weather_data.csv")

weather_subset = weatherdata[,c("PDT", "Max.TemperatureF", "Mean.TemperatureF", "Min.TemperatureF", "Mean.Humidity", "Mean.VisibilityMiles", "Mean.Wind.SpeedMPH", "Max.Gust.SpeedMPH", "PrecipitationIn", "CloudCover", "Events", "Zip")]

tripdata <- tripdata %>%
    mutate(StartDateTime = as.POSIXct(Start.Date, format = "%m/%d/%Y %H:%M", tz = "Pacific")) %>%
    mutate(EndDateTime = as.POSIXct(End.Date, format = "%m/%d/%Y %H:%M", tz = "Pacific")) %>%
    separate(Start.Date, into = c("StartDate", "StartTime"), sep = " ") %>%
    separate(End.Date, into = c("EndDate", "EndTime"), sep = " ") %>%
    rename(c("Bike.." = "Bike_number"))

results = data.frame()
for (i in 1:nrow(stationdata)) {
    address = revgeocode(c(stationdata[i,c("long")], stationdata[i,c("lat")]))
    results = rbind(results, data.frame("name" = stationdata[i,c("name")], "address" = address))
}

#saves results of station addresses to file
#write.csv(results, file = "station_addresses.csv")

#add address to stationdata, extract ZIP codes to new variable
stationdata = merge(results, stationdata)
stationdata$ZIP = ex_zip(stationdata$address)

#use station name to merge stationdata with tripdata, add only ZIPs to tripdata
#tripdata = merge(tripdata, stationdata[,c("name", "ZIP", "lat", "long")], by.x = "Start.Station", by.y = "name")
#tripdata_final = merge(tripdata, weather_subset, by.x = c("StartDate", "ZIP"), by.y = c("PDT", "Zip"))


#turn 'lat' and 'long' into start_lat and start_long; then create new end_lat and end_long f
#tripdata_final = transform(tripdata_final, start_lat = lat, start_long = long)

tripdata_final <- tripdata %>%
    merge(stationdata[,c("name", "ZIP", "lat", "long")], by.x = "Start.Station", by.y = "name") %>%
    merge(weather_subset, by.x = c("StartDate", "ZIP"), by.y = c("PDT", "Zip")) %>%
    transform(start_lat = lat, start_long = long) %>%
    subset(select = -c(lat, long)) %>%
    merge(stationdata[,c("name", "lat", "long")], by.x = "End.Station", by.y = "name") %>%
    transform(end_lat = lat, end_long = long) %>%
    subset(select = -c(lat, long))

for (i in 1:nrow(tripdata_final)) {
    start_long = tripdata_final[i,c("start_long")]
    start_lat = tripdata_final[i,c("start_lat")]
    end_long = tripdata_final[i,c("end_long")]
    end_lat = tripdata_final[i,c("end_lat")]
    tripdata_final$distGeo = distGeo(c(start_long, start_lat), c(end_long, end_lat))
}

#NOTE: giving all same distances...this is a problem...lag/long issues appear to be the source.
    
rownames(tripdata_final) <- tripdata_final$Trip.ID    


```

Notes:
Create variable w/trip distance
omit NAs
Remove massive outlier w/super long trip
Trace precipitation -> 'T': set to 0.


###Exploratory and Summary Plots
```{r}
hist(tripdata$Duration, breaks = 10000, xlim = c(0, 5000))

```


#Principal Components Analysis and Visualization

```{r}
tripdata_pca = tripdata[,c("Duration", "")]
```

#Clustering and Visualization







